\section{Background}
\subsection{Graph Computation and Sparse Matrix Operations}
The correspondence between graph representations and matrix operations establishes a fundamental duality that enables the expression of graph traversal problems through linear algebraic operations.
Given a weighted directed graph $G = \langle V, E, w \rangle$ where the edge set $E \subseteq V \times V$ consists of ordered pairs and the weight function $w$ maps edges to real numbers, 
we can construct an adjacency matrix $A \in \mathbb{R}^{|V| \times |V|}$ by numbering vertices from $0$ to $|V|-1$ and mapping each edge $(i,j)$ with weight $w(i,j)$ to the corresponding matrix element $A(i,j)$.
Conversely, any $N \times N$ matrix $A$ can be interpreted as representing a directed graph with $N$ vertices, where non-zero elements $A(i,j)$ correspond to edges with weights equal to their matrix values.
This bidirectional mapping provides a powerful framework for translating graph algorithms into matrix computational paradigms.

Matrix-vector multiplication $y = Ax$ essentially performs a one-step graph traversal: for each vertex $i$, 
it aggregates information from all vertices $j$ that have edges pointing to $i$, weighted by the corresponding edge weights $A(i,j)$.
Similarly, matrix-matrix multiplication computes multi-hop reachability—the product $A^k$ encodes $k$-hop paths in the graph, 
where element $(A^k)(i,j)$ represents accumulated weights along all $k$-length paths from vertex $j$ to vertex $i$.
However, standard arithmetic operations—addition for aggregation and multiplication for weight combination—only capture specific semantics 
like counting paths or computing probability flows.
To express diverse graph algorithms such as shortest paths, maximum flows, or graph connectivity, 
we need to generalize these operations beyond conventional arithmetic.
This generalization is achieved through semiring algebra, 
where we replace standard addition and multiplication with operations appropriate for the specific graph problem.

A practical example illustrates this concept: in shortest path problems, 
we can redefine matrix "addition" as taking the minimum value to select the shortest among multiple paths and matrix "multiplication" 
as standard addition to accumulate distances along a path.
Under these redefined operations, standard matrix multiplication automatically computes shortest paths between vertices.
By carefully choosing appropriate operations for different graph problems, 
sparse matrix computations can be adapted to solve a wide variety of graph algorithms efficiently~\cite{Tarjan}.

\subsection{Accelerator}
Graph processing applications suffer from poor performance on general-purpose processors due to irregular memory access patterns 
and low instruction-level parallelism caused by the sparse nature of real-world graphs. 
To address these limitations, dedicated graph accelerators have been developed to provide specialized hardware optimizations for graph computation workloads. 
The graph accelerator implements a vertex-centric processing model that addresses the fundamental irregularities in graph computation 
through a multi-layered optimization approach [1,2,3,4].

The core architecture employs a distributed processing approach where multiple processing elements (PEs) handle vertex computations in parallel. 
Each PE processes active vertices by traversing their associated edges and updating neighboring vertex properties through scatter and apply phases. 
To manage the data conflicts that arise when multiple vertices simultaneously update the same neighbor, 
the accelerator implements a parallel accumulator that exploits the commutative and associative properties of graph operations, 
allowing concurrent processing of conflicting updates while maintaining correctness [1].

The memory subsystem addresses the irregular access patterns inherent in graph processing through a two-tier approach 
that prioritizes frequently accessed graph data in high-speed on-chip memory while managing less critical data separately [2]. 
To support large-scale parallel processing, the accelerator uses a distributed memory design where each PE has its own local memory partition, 
connected through a mesh network rather than a traditional centralized interconnect, allowing the system to efficiently scale to over 1,024 PEs [3].

To facilitate evaluation and development, 
a comprehensive simulator has been designed for this graph accelerator that implements the complete instruction set architecture (ISA). 
The simulator supports assembly-level programming and accepts graph data in standard Compressed Sparse Row (CSR) format, 
enabling detailed performance analysis and algorithm validation. All experiments in this work are conducted using this simulator.